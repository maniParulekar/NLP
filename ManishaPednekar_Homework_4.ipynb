{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manisha Pednekar NLP Homework 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='BacktoTop'></a>\n",
    "## <font color=blue> Contents </font>\n",
    "- [Question 1a: NLTK Universal POS tagging Long Sentence](#section_ID1)\n",
    "- [Question 1b: NLTK Universal POS tagging Short Sentence](#section_ID2)\n",
    "- [Question 2: Pattern Penn POS tagging Long and Short Sentence](#section_ID3)\n",
    "- [Question 3: Differences between the two taggers and your manual tagging](#section_ID4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "import pattern\n",
    "from pattern.en import tag\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "short = \"Hello World!\"\n",
    "\n",
    "## long and news sentences are from \"https://www.cnn.com/2019/06/18/politics/mitch-mcconnell-nancy-pelosi-legislation-standoff/index.html\"\n",
    "long = \"McConnell's decision to methodically bar consideration of any of the House priorities already looms as a defining gamble in the GOP's effort to maintain its Senate majority in next year's election.\"\n",
    "news = \"But McConnell's blockade faces a new challenge as the House turns to a series of bills meant to fight foreign interference in the 2020 election.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltkTagger(sentence):\n",
    "    #to check length of a sentence\n",
    "    sentList = sentence.split(' ')\n",
    "    print('\\n -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\\n')\n",
    "    if (len(sentList)<=10):\n",
    "        print(\"\\t Short sentence of word length \", len(sentList))\n",
    "    else:\n",
    "        print(\"\\t Long sentence of word length \", len(sentList))\n",
    "        \n",
    "    print(\"\\n\\t\", sentence)\n",
    "    print('\\n -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\\n')\n",
    "    print(\"NLTK part of speech \\n\")\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    \n",
    "    tagged_sent = nltk.pos_tag(tokens, tagset='universal')\n",
    "    dfTag = pd.DataFrame(tagged_sent, columns = ['Word', 'POS'])\n",
    "    print (dfTag)\n",
    "\n",
    "def patternTagger(sentence):\n",
    "    #to check length of a sentence\n",
    "    sentList = sentence.split(' ')\n",
    "    print('\\n -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\\n')\n",
    "    if (len(sentList)<=10):\n",
    "        print(\"\\t Short sentence of word length \", len(sentList))\n",
    "    else:\n",
    "        print(\"\\t Long sentence of word length \", len(sentList))\n",
    "        \n",
    "    print(\"\\n\\t\", sentence)\n",
    "    print('\\n -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\\n')\n",
    "    print(\"Pattern library part of speech \\n\")\n",
    "    \n",
    "    tagged_sent = tag(sentence)\n",
    "    dfTag = pd.DataFrame(tagged_sent, columns = ['Word', 'POS'])\n",
    "    print (dfTag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_ID1\"></a>\n",
    "## Question 1a: NLTK Universal tagging Long Sentence\n",
    "<br>\n",
    "<font color=blue> 1a. Run one of the part-of-speech (POS) taggers available in Python. Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.</font>\n",
    "\n",
    "The python universal tag set which comes with NLTK library tags the chosen longest sentence correctly. This universal tag set has very limited POS tag categories compared to other POS tag sets present in the NLTK library. In my opinion, this tag set, as per it's small POS category set, **tags the longest sentence quite correctly**. The output is shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "\t Long sentence of word length  31\n",
      "\n",
      "\t McConnell's decision to methodically bar consideration of any of the House priorities already looms as a defining gamble in the GOP's effort to maintain its Senate majority in next year's election.\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "NLTK part of speech \n",
      "\n",
      "             Word   POS\n",
      "0       McConnell  NOUN\n",
      "1              's   PRT\n",
      "2        decision  NOUN\n",
      "3              to   PRT\n",
      "4    methodically   ADV\n",
      "5             bar  VERB\n",
      "6   consideration  NOUN\n",
      "7              of   ADP\n",
      "8             any   DET\n",
      "9              of   ADP\n",
      "10            the   DET\n",
      "11          House  NOUN\n",
      "12     priorities  NOUN\n",
      "13        already   ADV\n",
      "14          looms  VERB\n",
      "15             as   ADP\n",
      "16              a   DET\n",
      "17       defining  VERB\n",
      "18         gamble  NOUN\n",
      "19             in   ADP\n",
      "20            the   DET\n",
      "21            GOP  NOUN\n",
      "22             's   PRT\n",
      "23         effort  NOUN\n",
      "24             to   PRT\n",
      "25       maintain  VERB\n",
      "26            its  PRON\n",
      "27         Senate  NOUN\n",
      "28       majority  NOUN\n",
      "29             in   ADP\n",
      "30           next   ADJ\n",
      "31           year  NOUN\n",
      "32             's   PRT\n",
      "33       election  NOUN\n",
      "34              .     .\n"
     ]
    }
   ],
   "source": [
    "##-----------------Long Sentence------------------------##\n",
    "nltkTagger(long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#BacktoTop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_ID2\"></a>\n",
    "## Question 1b:  NLTK Universal pos tagging Short Sentence\n",
    "<br>\n",
    "<font color=blue> 1b. Find the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture(an opinion or conclusion formed on the basis of incomplete information) as to why the tagger might have been less than perfect with this sentence. </font>\n",
    "\n",
    " I chose 2 short sentences to run the universal tagger for question 1b. The word \"Hello\" from the sentence \"Hello World!\" is not tagged correctly since there is no specific category present in this tag set to encompass interjections part of speech. Since 'H' of \"Hello\" is in upper case in this sentence and also \"Hello\" is followed by a noun, this tagger tags Hello as noun. If the sentence has 'H' of \"Hello\" in lower case, it will recognize it as Adjective since it is followed by a noun \"world\". To prove that this tagger tags interjections as adjective or adposition, I ran the tagger on a different sentence \"Oops I did it again\" which starts with Interjection \"Oops\". In this case, the tagger tags \"Oops\" as Adposition since it is followed by a pronoun in this sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "\t Short sentence of word length  2\n",
      "\n",
      "\t Hello World!\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "NLTK part of speech \n",
      "\n",
      "    Word   POS\n",
      "0  Hello  NOUN\n",
      "1  World  NOUN\n",
      "2      !     .\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "\t Short sentence of word length  2\n",
      "\n",
      "\t hello world!\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "NLTK part of speech \n",
      "\n",
      "    Word   POS\n",
      "0  hello   ADJ\n",
      "1  world  NOUN\n",
      "2      !     .\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "\t Short sentence of word length  5\n",
      "\n",
      "\t Oops I did it again\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "NLTK part of speech \n",
      "\n",
      "    Word   POS\n",
      "0   Oops   ADP\n",
      "1      I  PRON\n",
      "2    did  VERB\n",
      "3     it  PRON\n",
      "4  again   ADV\n"
     ]
    }
   ],
   "source": [
    "##-----------------Short Sentence------------------------##\n",
    "nltkTagger(short)\n",
    "\n",
    "##-----------Another Short Sentence------------------------##\n",
    "anotherShort = \"hello world!\"\n",
    "nltkTagger(anotherShort)\n",
    "\n",
    "##-----------Another interesting Short Sentence ------------------------##\n",
    "anotherShort = \"Oops I did it again\"\n",
    "nltkTagger(anotherShort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#BacktoTop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_ID3\"></a>\n",
    "## Question 2:  Pattern Penn POS tagging Long and Short Sentence\n",
    "<br>\n",
    "<font color=blue> 2. Run a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "a.\tDoes it produce the same or different output?\n",
    "b.\tExplain any differences as best you can\n",
    " </font>\n",
    "\n",
    "Yes, it does produce different results for the both sentences long and short with two different tagging methods. Pattern library tag function use Penn treebank tag set which more refined tagging method over Universal tag set from NLTK library. Penn treebank improves POS tagging of sentences by adding more specific tag categories for part of speech. For eg: \"defining\" from the long sentence is tagged as 'verb' by Universal tag set and it is tagged as 'verb gerand' by Penn tree bank. In case of \"McConnel's\" from Long sentence, the apostrophe 's' forming possessive nouns are categorized with specific POS tag catergory of 'POS' (Possessive ending) in Penn whereas it is tagged as 'PRT' which is 'particle' instead of a more elaborate \"Particle possesive\" by Universal. Pronouns like \"its\" tagged as 'PRPS' (Possessive pronoun) in Penn and as Pron in Universal. \"to\" is categoried as 'TO' by Penn and as 'PRT' in Universal.\n",
    "\n",
    "Even though, parts of speech tagging can be important for syntactic and semantic analysis, I noticed that the POS tagging is **not always correct** by both methods.  In case of Long sentence, the universal tagger tags \"bar\" as verb which is correct, but the Penn treebank tagger tags \"bar\" as \"Noun\" which is incorrect. In case of short sentences, Penn treebank tagger tags \"Oops\" or \"Hello\" correctly as Interjection whereas Universal tagger tags them incorrect as Noun . I think one of the differnce we see between two tagger is due to the fact that one tagger is more generalized than the other. But, there are differnces in tagging between these two taggers which cannot be explained even if we notice that both the tagger take the preceding word and succceeding word tag analysis into account while tagging the words of a sentence. **Overall, both tagging sets are not perfect but the Penn POS tagger does yield pretty accurate and precise results**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "\t Short sentence of word length  2\n",
      "\n",
      "\t Hello World!\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "Pattern library part of speech \n",
      "\n",
      "    Word  POS\n",
      "0  Hello   UH\n",
      "1  World  NNP\n",
      "2      !    .\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "\t Long sentence of word length  31\n",
      "\n",
      "\t McConnell's decision to methodically bar consideration of any of the House priorities already looms as a defining gamble in the GOP's effort to maintain its Senate majority in next year's election.\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "Pattern library part of speech \n",
      "\n",
      "             Word   POS\n",
      "0       McConnell   NNP\n",
      "1              's   POS\n",
      "2        decision    NN\n",
      "3              to    TO\n",
      "4    methodically    RB\n",
      "5             bar    NN\n",
      "6   consideration    NN\n",
      "7              of    IN\n",
      "8             any    DT\n",
      "9              of    IN\n",
      "10            the    DT\n",
      "11          House   NNP\n",
      "12     priorities   NNS\n",
      "13        already    RB\n",
      "14          looms   VBZ\n",
      "15             as    IN\n",
      "16              a    DT\n",
      "17       defining   VBG\n",
      "18         gamble    NN\n",
      "19             in    IN\n",
      "20            the    DT\n",
      "21            GOP   NNP\n",
      "22             's   POS\n",
      "23         effort    NN\n",
      "24             to    TO\n",
      "25       maintain    VB\n",
      "26            its  PRP$\n",
      "27         Senate   NNP\n",
      "28       majority    NN\n",
      "29             in    IN\n",
      "30           next    JJ\n",
      "31           year    NN\n",
      "32             's   POS\n",
      "33       election    NN\n",
      "34              .     .\n"
     ]
    }
   ],
   "source": [
    "patternTagger(short)\n",
    "\n",
    "#patternTagger(anotherShort)\n",
    "##-----------------Long Sentence------------------------##\n",
    "patternTagger(long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#BacktoTop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_ID4\"></a>\n",
    "## Question 3:  Differences between the two taggers and your manual tagging\n",
    "<br>\n",
    "<font color=blue> 3.\tIn a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "a.\tLooking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    "c.\tExplain any differences between the two taggers and your manual tagging as much as you can.\n",
    " </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********------------Question 3. News Article sentence----------************\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "\t Long sentence of word length  25\n",
      "\n",
      "\t But McConnell's blockade faces a new challenge as the House turns to a series of bills meant to fight foreign interference in the 2020 election.\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "NLTK part of speech \n",
      "\n",
      "            Word   POS\n",
      "0            But  CONJ\n",
      "1      McConnell  NOUN\n",
      "2             's   PRT\n",
      "3       blockade  NOUN\n",
      "4          faces  VERB\n",
      "5              a   DET\n",
      "6            new   ADJ\n",
      "7      challenge  NOUN\n",
      "8             as   ADP\n",
      "9            the   DET\n",
      "10         House  NOUN\n",
      "11         turns  VERB\n",
      "12            to   PRT\n",
      "13             a   DET\n",
      "14        series  NOUN\n",
      "15            of   ADP\n",
      "16         bills  NOUN\n",
      "17         meant  VERB\n",
      "18            to   PRT\n",
      "19         fight  VERB\n",
      "20       foreign   ADJ\n",
      "21  interference  NOUN\n",
      "22            in   ADP\n",
      "23           the   DET\n",
      "24          2020   NUM\n",
      "25      election  NOUN\n",
      "26             .     .\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "\t Long sentence of word length  25\n",
      "\n",
      "\t But McConnell's blockade faces a new challenge as the House turns to a series of bills meant to fight foreign interference in the 2020 election.\n",
      "\n",
      " -=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=--=-=-=-=-=-=-=-=-=-=\n",
      "\n",
      "Pattern library part of speech \n",
      "\n",
      "            Word  POS\n",
      "0            But   CC\n",
      "1      McConnell  NNP\n",
      "2             's  POS\n",
      "3       blockade   NN\n",
      "4          faces  VBZ\n",
      "5              a   DT\n",
      "6            new   JJ\n",
      "7      challenge   NN\n",
      "8             as   IN\n",
      "9            the   DT\n",
      "10         House  NNP\n",
      "11         turns  VBZ\n",
      "12            to   TO\n",
      "13             a   DT\n",
      "14        series   NN\n",
      "15            of   IN\n",
      "16         bills  NNS\n",
      "17         meant  VBD\n",
      "18            to   TO\n",
      "19         fight   VB\n",
      "20       foreign   JJ\n",
      "21  interference   NN\n",
      "22            in   IN\n",
      "23           the   DT\n",
      "24          2020   CD\n",
      "25      election   NN\n",
      "26             .    .\n"
     ]
    }
   ],
   "source": [
    "##-----------------News Sentence------------------------##\n",
    "print(\"**********------------Question 3. News Article sentence----------************\")\n",
    "nltkTagger(news)\n",
    "\n",
    "patternTagger(news)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pattern's Penn tree tagger produced exactly same results with my results using Penn tag set. One of the reason for matching tagging with mine and Pattern tagger is that the tag set utilized for tagging is same. I think I will choose Penn tree tag set taggers for POS tagging task more than any other tagger in future since Penn tree tag set encompasses appropriate Part-Of-Speech for English language.\n",
    "\n",
    "As we observed earlier with long and short sentence tagging, Universal tag set **mark core part of speech categories** most of the time correctly. To **distinguish additional lexical and grammatical properties of words**, I would use the Pattern Penn tagger. In case of news article sentence too, we observed the same differences in tagging as earlier mentioned in the answser to question 2 above. For eg: \"as\" is tagged 'IN' in Penn and as ADP in Universal, \"House\" is tagged NNP in Penn and as Noun in Universal, \"bills\" as NNS in Penn and as Noun in Universal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>By Hand</th>\n",
       "      <th>Penn Treebank</th>\n",
       "      <th>Universal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>But</td>\n",
       "      <td>CC</td>\n",
       "      <td>CC</td>\n",
       "      <td>CONJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McConnell</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'s</td>\n",
       "      <td>POS</td>\n",
       "      <td>POS</td>\n",
       "      <td>PRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blockade</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>faces</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>new</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>challenge</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>as</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>House</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>turns</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VBZ</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "      <td>PRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>series</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bills</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>meant</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>TO</td>\n",
       "      <td>PRT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fight</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>VERB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>foreign</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>ADJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>interference</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>IN</td>\n",
       "      <td>ADP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>DT</td>\n",
       "      <td>DET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>election</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>NOUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           words By Hand Penn Treebank Universal\n",
       "0            But      CC            CC      CONJ\n",
       "1      McConnell     NNP           NNP      NOUN\n",
       "2             's     POS           POS       PRT\n",
       "3       blockade      NN            NN      NOUN\n",
       "4          faces     VBZ           VBZ      VERB\n",
       "5              a      DT            DT       DET\n",
       "6            new      JJ            JJ       ADJ\n",
       "7      challenge      NN            NN      NOUN\n",
       "8             as      IN            IN       ADP\n",
       "9            the      DT            DT       DET\n",
       "10         House     NNP           NNP      NOUN\n",
       "11         turns     VBZ           VBZ      VERB\n",
       "12            to      TO            TO       PRT\n",
       "13             a      DT            DT       DET\n",
       "14        series      NN            NN      NOUN\n",
       "15            of      IN            IN       ADP\n",
       "16         bills     NNS           NNS      NOUN\n",
       "17         meant     VBD           VBD      VERB\n",
       "18            to      TO            TO       PRT\n",
       "19         fight      VB            VB      VERB\n",
       "20       foreign      JJ            JJ       ADJ\n",
       "21  interference      NN            NN      NOUN\n",
       "22            in      IN            IN       ADP\n",
       "23           the      DT            DT       DET\n",
       "24          2020      CD            CD       NUM\n",
       "25      election      NN            NN      NOUN\n",
       "26             .       .             .         ."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [('But', 'CC', 'CC', 'CONJ'),('McConnell', 'NNP', 'NNP', 'NOUN'),(\"'s\", 'POS', 'POS', 'PRT'),\n",
    " ('blockade', 'NN', 'NN', 'NOUN'),('faces', 'VBZ', 'VBZ', 'VERB'),('a', 'DT', 'DT', 'DET'),('new', 'JJ', 'JJ', 'ADJ'),\n",
    " ('challenge', 'NN', 'NN', 'NOUN'),('as', 'IN', 'IN', 'ADP'),('the', 'DT', 'DT', 'DET'),('House', 'NNP', 'NNP', 'NOUN'),\n",
    " ('turns', 'VBZ', 'VBZ', 'VERB'),('to', 'TO', 'TO', 'PRT'),('a', 'DT', 'DT', 'DET'),('series', 'NN', 'NN', 'NOUN'),\n",
    " ('of', 'IN', 'IN', 'ADP'),('bills', 'NNS', 'NNS', 'NOUN'),('meant', 'VBD', 'VBD', 'VERB'),('to', 'TO', 'TO', 'PRT'),\n",
    " ('fight', 'VB', 'VB', 'VERB'),('foreign', 'JJ', 'JJ', 'ADJ'),('interference', 'NN', 'NN', 'NOUN'),('in', 'IN', 'IN', 'ADP'),\n",
    " ('the', 'DT', 'DT', 'DET'),('2020', 'CD', 'CD', 'NUM'),('election', 'NN', 'NN', 'NOUN'),('.', '.', '.', '.')]\n",
    "\n",
    "df = pd.DataFrame(lst, columns =['words', 'By Hand', 'Penn Treebank','Universal'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#BacktoTop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
