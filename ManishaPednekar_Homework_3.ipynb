{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manisha Pednekar NLP Homework 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='BacktoTop'></a>\n",
    "## <font color=blue> Contents </font>\n",
    "- [Question 1 Edit Distances](#section_ID1)\n",
    "- [Question 2: Stop Word Elimination](#section_ID2)\n",
    "- [Question 3: Stemming](#section_ID3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.metrics import * ## Q1a\n",
    "\n",
    "from nltk import word_tokenize ## Q2\n",
    "\n",
    "from nltk.stem import PorterStemmer ## Q3\n",
    "\n",
    "from nltk.stem import LancasterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_ID1\"></a>\n",
    "## Question 1: Edit Distances\n",
    "<br>\n",
    "<font color=blue> 1a. Compare your given name with your nickname. What is the edit distance between your nickname and your given name?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The edit distance between your nickname and your given name is 3\n"
     ]
    }
   ],
   "source": [
    "### Given Name: \"Manisha\"  Pet Name: \"Mani\"\n",
    "distNamePetNm= edit_distance(\"Manisha\", \"Mani\")\n",
    "print(\"The edit distance between your nickname and your given name is\", distNamePetNm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> 1b. What is the percentage string match between your nickname and your given name? </font>\n",
    "\n",
    "    4 letters match out of 7, thus Percetage string match = 4/7= 0.57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#BacktoTop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_ID2\"></a>\n",
    "<font color=blue> 1b. Find a friend (or family member or classmate) who you know has read a certain book. Without your friend knowing, copy the first two sentences of that book. Now rewrite the words from those sentences, excluding stop words. Now tell your friend to guess which book the words are from by reading them just that list of words. Did you friend correctly guess the book on the first try? What did he or she guess? Explain why you think you friend either was or was not able to guess the book from hearing the list of words. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['little', 'villagers', 'ivy', 'many', 'missing', 'riddle', 'roof', 'spreading', 'though', 'lived', 'stood', 'windows', 'years', 'unchecked', 'family', 'face', 'village', 'boarded', 'tiles', 'house', 'hill', 'since', 'hangleton', 'still', 'called', 'overlooking', 'even']\n"
     ]
    }
   ],
   "source": [
    "bookStr = \"The villagers of Little Hangleton still called it \\\"the Riddle House\\\", even though it \\\n",
    "had been many years since the Riddle family had lived there. It stood on a hill\\\n",
    " overlooking the village, some of its windows boarded, tiles missing from its roof,\\\n",
    " and ivy spreading unchecked over its face.\"\n",
    " \n",
    "tokens = word_tokenize(bookStr)\n",
    "        # convert to lower case\n",
    "tokens = [w.lower() for w in tokens]\n",
    "# remove all tokens that are not alphabetic\n",
    "words = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "words= set(words)\n",
    "\n",
    "## Function remove_stopwords is from  DipanjanSarkar's code:\n",
    "## https://github.com/dipanjanS/text-analytics-with-python/blob/master/Old-First-Edition/source_code/Ch03_Processing_and_Understanding_Text/normalizer.py\n",
    "def remove_stopwords(tokens):\n",
    "    stopword_list = nltk.corpus.stopwords.words('english')\n",
    "    filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    return filtered_tokens\n",
    "\n",
    "zeroStopWds = remove_stopwords(words)\n",
    "print(zeroStopWds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> \"The villagers of Little Hangleton still called it \"the Riddle House\", even though it had been many years since the Riddle family had lived there. It stood on a hill overlooking the village, some of its windows boarded, tiles missing from its roof, and ivy spreading unchecked over its face.\" – Harry Potter and the goblet of Fire by J.K. Rowling </font>\n",
    "<br>\n",
    "<font color=blue> Did you friend correctly guess the book on the first try? What did he or she guess? </font>\n",
    "\n",
    "My friend recognized the book series (though not specific volume) on the first try. Moreover, he summarized the main events from the chapter one of this book by seeing the words from first two lines of the book.\n",
    "<br>\n",
    "<font color=blue> Explain why you think you friend either was or was not able to guess the book from hearing the list of words.</font>\n",
    "\n",
    "The list of the words contained the content words without duplicate words. This list included two unique proper nouns (Hangleton and Riddle) and these characterizing nouns were helpful in identifying the book series. Also, one proper noun out of two, was followed by a common noun (riddle house) which gave out major clue about the plot of the main event of the chapter one from this book.  As per my friend, the words like “Hangleton”, “riddle house”, “missing tiles”, “ivy spreading” were helpful in recognizing which particular Harry Potter series book it is. My friend had read all Harry Potter series books and some of the books he read twice six years ago, but he is a fan of Harry Potter series books, thus I think he was able to recognize the book title correctly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#BacktoTop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_ID3\"></a>\n",
    "<font color=blue> 3. Run one of the stemmers available in Python. Run the same two sentences from question 2 above through the stemmer and show the results. How many of the outputted stems are valid morphological roots of the corresponding words? Express this answer as a percentage. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter Stemmer:  ['littl', 'villag', 'ivi', 'mani', 'miss', 'riddl', 'roof', 'spread', 'though', 'live', 'stood', 'window', 'year', 'uncheck', 'famili', 'face', 'villag', 'board', 'tile', 'hous', 'hill', 'sinc', 'hangleton', 'still', 'call', 'overlook', 'even']\n"
     ]
    }
   ],
   "source": [
    "########----------Q3\n",
    "# Porter stemmer\n",
    "ps = PorterStemmer()\n",
    "     \n",
    "stemList = []\n",
    "for w in zeroStopWds:\n",
    "    stemList.append(ps.stem(w))\n",
    "    \n",
    "print(\"Porter Stemmer: \",stemList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lancaster Stemmer:  ['littl', 'vil', 'ivy', 'many', 'miss', 'riddl', 'roof', 'spreading', 'though', 'liv', 'stood', 'window', 'year', 'uncheck', 'famy', 'fac', 'vil', 'board', 'til', 'hous', 'hil', 'sint', 'hangleton', 'stil', 'cal', 'overlook', 'ev']\n"
     ]
    }
   ],
   "source": [
    "# Lancaster Stemmer\n",
    "ls = LancasterStemmer()\n",
    "\n",
    "LanStemList = []\n",
    "for w in zeroStopWds:\n",
    "    LanStemList.append(ls.stem(w))\n",
    "\n",
    "print(\"Lancaster Stemmer: \", LanStemList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization:  ['littl', 'vil', 'ivy', 'many', 'miss', 'riddl', 'roof', 'spreading', 'though', 'liv', 'stood', 'window', 'year', 'uncheck', 'famy', 'fac', 'vil', 'board', 'til', 'hous', 'hil', 'sint', 'hangleton', 'stil', 'cal', 'overlook', 'ev']\n"
     ]
    }
   ],
   "source": [
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "\n",
    "lemmaList = []\n",
    "for w in zeroStopWds:\n",
    "    lemmaList.append(wnl.lemmatize(w))\n",
    "\n",
    "print(\"Lemmatization: \", LanStemList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> How many of the outputted stems are valid morphological roots of the corresponding words? \n",
    "Express this answer as a percentage. </font>\n",
    "\n",
    "- Porter Stem – 9 of 27 stems are not valid morphological root.\n",
    "66.66% are valid morphological roots.\n",
    "<br>\n",
    "\n",
    "- Snowball Stem\n",
    "– 14 of 27 stems are not valid morphological roots. 48.14% are valid morphological roots.\n",
    "<br>\n",
    "\n",
    "- Lemmatization\n",
    "– 14 of 27 lemmas are not valid morphological roots. 48.14% are valid morphological roots."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to the top](#BacktoTop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
